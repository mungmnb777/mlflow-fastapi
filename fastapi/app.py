import mlflow
import mlflow.pyfunc
from mlflow.tracking import MlflowClient
from fastapi import FastAPI
from pydantic import BaseModel
import numpy as np

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()

# MLflow ì„¤ì •
mlflow.set_tracking_uri("http://mlflow-server:5000")
model_name = "study_hours_regressor"

# âœ… ìµœì‹  ëª¨ë¸ ë²„ì „ ê°€ì ¸ì˜¤ê¸°
client = MlflowClient()
latest_version = max([
    int(m.version) for m in client.search_model_versions(f"name='{model_name}'")
])

# âœ… ìµœì‹  ëª¨ë¸ ë¡œë“œ
model_uri = f"models:/{model_name}/{latest_version}"
model = mlflow.pyfunc.load_model(model_uri)


# ğŸ“Œ ìš”ì²­ ë°ì´í„° í˜•ì‹ ì •ì˜
class StudyHoursInput(BaseModel):
    study_hours: float

@app.get("/")
def root():
    return {"message": "MLflow Model API is running!"}

# âœ… ì˜ˆì¸¡ API ì—”ë“œí¬ì¸íŠ¸
@app.post("/predict")
def predict(input_data: StudyHoursInput):
    try:
        # ì…ë ¥ ë°ì´í„° ì²˜ë¦¬
        X_input = np.array([[input_data.study_hours]])
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        prediction = model.predict(X_input)
        
        return {
            "study_hours": input_data.study_hours,
            "predicted_test_score": float(prediction[0])
        }
    
    except Exception as e:
        return {"error": str(e)}

# FastAPI ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
